{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use on-demand test objective functions (e.g. bimodal) to help calibrate surrogate functions and acquisition functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic, RBF, Matern, DotProduct, WhiteKernel\n",
    "from mbbo.output import format_for_submission, output_results_csv, ScenarioResult, TestResults #!pip install -e .\n",
    "from mbbo.test_gaussian import one_d_test, two_d_test, n_d_test\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(51)\n",
    "np.random.seed(51)\n",
    "\n",
    "week1_out = [0.0, -0.03634716524130564, -0.13995571712281177, -11.512791229057324, 351.7115420928652, -0.5971511450896173, 0.2910786825809617, 8.618272750952901]\n",
    "week1_in = [np.array([0.00367, 0.9999 ]), \n",
    "            np.array([0.851999, 0.973204]), \n",
    "            np.array([0.747032, 0.28413 , 0.226329]), \n",
    "            np.array([0.169128, 0.756136, 0.275457, 0.528761]), \n",
    "            np.array([0.439601, 0.772709, 0.376277, 0.933269]), \n",
    "            np.array([0.232204, 0.132714, 0.53824 , 0.760706, 0.075595]), \n",
    "            np.array([0.476821, 0.248196, 0.242816, 0.576157, 0.162416, 0.290926]), \n",
    "            np.array([0.221603, 0.703755, 0.674607, 0.130295, 0.376739, 0.669444, 0.136655, 0.061316])]    \n",
    "\n",
    "week2_out = [-1.2075460499722905e-18, 0.17608630702211278, -0.17239781799687137, -31.982880235497266, 1236.8846557000643, -2.451406055102475, 0.00010805707939840242, 5.178959940699899]\n",
    "week2_in = [np.array([0.476035, 0.572563]), \n",
    "            np.array([0.641846, 0.498841]), \n",
    "            np.array([0., 0., 0.]), \n",
    "            np.array([0.953433, 0.895217, 0.812477, 0.618719]), \n",
    "            np.array([0.987523, 0.470227, 0.946409, 0.105412]), \n",
    "            np.array([3.40696e-01, 4.94179e-01, 2.10000e-05, 3.08050e-02, 9.39958e-01]), \n",
    "            np.array([0.88314 , 0.756642, 0.      , 0.      , 0.9     , 0.942719]), \n",
    "            np.array([0.993634, 0.968223, 0.979285, 0.397318, 0.965856, 0.955218, 0.006078, 0.024001])]\n",
    "\n",
    "week3_out = [-2.118633970077695e-95, -0.1068943462941895, -0.005838531351604155, -2.6718044713157307, 32.0025, -1.4580645404618957, 0.4892165178828796, 9.9417237968706]\n",
    "\n",
    "week3_in = [np.array([0.127849, 0.198491]), \n",
    "            np.array([0.246077, 0.656597]), \n",
    "            np.array([0.492581, 0.611593, 0.5     ]), \n",
    "            np.array([0.510358, 0.521985, 0.383995, 0.445439]), \n",
    "            np.array([0.5, 0.5, 0.5, 0.5]), \n",
    "            np.array([0.66336 , 0.      , 0.999999, 0.332984, 0.      ]), \n",
    "            np.array([0.      , 0.165185, 0.28681 , 0.      , 0.318109, 0.999999]), \n",
    "            np.array([0.119265, 0.254466, 0.117275, 0.24563 , 0.548426, 0.553172,  0.230111, 0.516062])]\n",
    "\n",
    "week4_out = [-8.306597721001677e-27, 0.715790799340666, -0.00506242600241439, -3.2126105576284227, 31.94090504001378, -0.9205277885179105, 0.3911680928412005, 9.6899612812574]\n",
    "\n",
    "week4_in = [np.array([0.24001 , 0.357107]),\n",
    "                np.array([0.5, 0.5]), \n",
    "                np.array([0.5, 0.5, 0.5]), \n",
    "                np.array([0.549669, 0.508442, 0.413776, 0.413008]), \n",
    "                np.array([0.500102, 0.500102, 0.500102, 0.500102]), \n",
    "                np.array([0.563405, 0.      , 0.83134 , 0.999999, 0.      ]), \n",
    "                np.array([0.      , 0.626234, 0.280125, 0.      , 0.36777 , 0.451863]), \n",
    "                np.array([0.275027, 0.304704, 0.160147, 0.328388, 0.419169, 0.578759, 0.436166, 0.614079])]\n",
    "\n",
    "week5_out = [1.517648729565899e-192, 0.509599138595138, -0.025681820315624142, -4.078914281244423, 629.9338529410855, -1.747233852094004, 0.39256467139392903, 9.7675674964181]\n",
    "\n",
    "week5_in = [np.array([0.999999, 0.999999]), np.array([0.666698, 0.666698]), np.array([0.558875, 0.558874, 0.558875]), np.array([0.523385, 0.494608, 0.22783 , 0.357468]), np.array([0.932544, 0.415248, 0.89143 , 0.050433]), np.array([0.      , 0.687353, 0.      , 0.999999, 0.      ]), np.array([0.      , 0.56895 , 0.354465, 0.290165, 0.482077, 0.989692]), np.array([0.      , 0.047944, 0.315163, 0.115808, 0.571106, 0.59513 ,\n",
    "       0.376754, 0.548807])]\n",
    "\n",
    "def get_function_data(function_number):\n",
    "    ary_in = np.load(f'../data/raw/initial_data/function_{function_number}/initial_inputs.npy')\n",
    "    ary_out = np.load(f'../data/raw/initial_data/function_{function_number}/initial_outputs.npy')\n",
    "\n",
    "    \n",
    "\n",
    "    ary_out=np.append(ary_out, week1_out[function_number-1])\n",
    "    ary_out=np.append(ary_out, week2_out[function_number-1])\n",
    "    ary_out=np.append(ary_out, week3_out[function_number-1])\n",
    "    ary_out=np.append(ary_out, week4_out[function_number-1])\n",
    "    ary_out=np.append(ary_out, week5_out[function_number-1])\n",
    "    ary_in=np.vstack((ary_in, week1_in[function_number-1]))\n",
    "    ary_in=np.vstack((ary_in, week2_in[function_number-1]))\n",
    "    ary_in=np.vstack((ary_in, week3_in[function_number-1]))\n",
    "    ary_in=np.vstack((ary_in, week4_in[function_number-1]))\n",
    "    ary_in=np.vstack((ary_in, week5_in[function_number-1]))\n",
    "    \n",
    "    return ary_in, ary_out\n",
    "\n",
    "class FunctionInfo():\n",
    "    rbf_lengthscales = [0.8, 0.001, 0.016, 0.337, 0.0162, 0.68, 0.644, 1.0 ] # functions 2 and 8 didn't find optimal lengthscale in training\n",
    "    ucb_kappas = [0.1, 1.1, 0.00001, 0.8, 0.4, 0.8, 0.8, 0.8] # only got successful calibration for first 3. Default to 0.8 for the rest (high because still exploring) \n",
    "                                                              # - except function 5 which is unimodal so can exploit more.\n",
    "                                                              # Function 3 - aim is to reduce bad side effects of drug combination - have a maximum around 0.5,0.5,0.5 so from week 5 on, exploiting that\n",
    "    perturb_max_starts = [0,0,0,0,-0.055,0,0,0] #having trouble getting function 5 to explore a little more away from its maximum - nudge\n",
    "    kernel_params_list=[{\"class\": \"RationalQuadratic\", \"alpha\": 0.4},\n",
    "                   {\"class\": \"RationalQuadratic\", \"alpha\": 1.0},\n",
    "                   {\"class\": \"RationalQuadratic\", \"alpha\": 1.0},\n",
    "                   {\"class\": \"RationalQuadratic\", \"alpha\": 1.0}, #f4 - all NaN\n",
    "                   {\"class\": \"RationalQuadratic\", \"alpha\": 1.4}, #f5 = mainly NaN\n",
    "                   {\"class\": \"Matern52\", \"nu\":2.5}, #f6 - mainly NaN\n",
    "                   {\"class\": \"RationalQuadratic\", \"alpha\": 1.0},\n",
    "                   {\"class\": \"RationalQuadratic\", \"alpha\": 1.0}]\n",
    "\n",
    "    def __init__(self, function_number):\n",
    "        self.function_number = function_number\n",
    "        function_ix = function_number - 1\n",
    "        self.kernel_lengthscale = self.rbf_lengthscales[function_ix]\n",
    "        self.ucb_kappa = self.ucb_kappas[function_ix]\n",
    "        self.kernel_params = self.kernel_params_list[function_ix]\n",
    "        self.perturb_max_start = self.perturb_max_starts[function_ix]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check progress so far\n",
    "\n",
    "responses = [week1_out, week2_out, week3_out, week4_out, week5_out]\n",
    "\n",
    "for i in range(1,9):\n",
    "    initial_data = np.load(f'../data/raw/initial_data/function_{i}/initial_outputs.npy')\n",
    "    for week in range(1, 4):\n",
    "        response = responses[week-1][i-1]\n",
    "        if response > max(initial_data):\n",
    "            print(f\"Function {i} - week {week} improved on initial values - {response} over {max(initial_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function 3 - \"(hint: one of the variables may not cause any effects on the person).\"\n",
    "X, y = get_function_data(3)\n",
    "\n",
    "#1. Simple correlations\n",
    "correlations = []\n",
    "for i in range(X.shape[1]):\n",
    "    corr_matrix = np.corrcoef(X[:, i], y)\n",
    "    corr = corr_matrix[0, 1]  # correlation between dimension i and y\n",
    "    correlations.append(corr)\n",
    "print(\"Simple correlations:\")\n",
    "for i, corr in enumerate(correlations):\n",
    "    print(f\"Dimension {i}: correlation with output = {corr:.4f}\")\n",
    "\n",
    "#2 Coefficients from linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "coeffs = model.coef_\n",
    "intercept = model.intercept_\n",
    "print(\"Linear regression:\")\n",
    "print(f\"Coefficients: {coeffs}\")\n",
    "print(f\"Intercept: {intercept}\")\n",
    " #3 Features importance from random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=51)\n",
    "rf.fit(X, y)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "print(\"Random forest:\")\n",
    "for i, imp in enumerate(importances):\n",
    "    print(f\"Dimension {i}: importance = {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 1.32E-79 -> Scaled: 0.2262\n",
      "Original: 1.03E-46 -> Scaled: 0.5592\n",
      "Original: 7.71E-16 -> Scaled: 0.8717\n",
      "Original: 3.34E-124 -> Scaled: 0.2253\n",
      "Original: -3.61E-03 -> Scaled: -1.0000\n",
      "Original: -2.16E-54 -> Scaled: -0.4814\n",
      "Original: -2.09E-91 -> Scaled: -0.1067\n",
      "Original: 2.54E-40 -> Scaled: 0.6239\n",
      "Original: 3.61E-81 -> Scaled: 0.2104\n",
      "Original: 6.23E-48 -> Scaled: 0.5468\n",
      "Original: 0.00E+00 -> Scaled: 0.0000\n",
      "Original: -1.21E-18 -> Scaled: -0.8433\n",
      "Original: -2.12E-95 -> Scaled: -0.0663\n",
      "Original: -8.31E-27 -> Scaled: -0.7607\n",
      "Original: 1.52E-192 -> Scaled: 0.9172\n"
     ]
    }
   ],
   "source": [
    "#function 1 - values mostly very close to 0\n",
    "def scale_f1(values):\n",
    "    # Step 1: Replace zeros with a small positive value to avoid log(0)\n",
    "    epsilon = 1e-200  # A very small number\n",
    "    values_safe = np.where(values == 0, epsilon, values)\n",
    "\n",
    "    # Step 2: Take the logarithm of absolute values\n",
    "    log_values = np.log10(np.abs(values_safe))\n",
    "\n",
    "    # Step 3: Normalize to the range [-1, 1]\n",
    "    log_min, log_max = np.min(log_values), np.max(log_values)\n",
    "    scaled_values = 2 * (log_values - log_min) / (log_max - log_min) - 1\n",
    "\n",
    "    # Step 4: Restore signs\n",
    "    return np.sign(values) * np.abs(scaled_values)\n",
    "\n",
    "f1_in, f1_out = get_function_data(1)\n",
    "f1_out_scaled = scale_f1(f1_out) \n",
    "for original, scaled in zip(f1_out ,f1_out_scaled):\n",
    "    print(f\"Original: {original:.2E} -> Scaled: {scaled:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_twod_objective(twod):\n",
    "\n",
    "    N = 100\n",
    "    x0_vals = np.linspace(0, 1, N)\n",
    "    x1_vals = np.linspace(0, 1, N)\n",
    "    X0, X1 = np.meshgrid(x0_vals, x1_vals)        # shape (N, N) each\n",
    "    X_grid = np.column_stack((X0.ravel(), X1.ravel()))  # shape (N*N, 2)\n",
    "\n",
    "    y_grid  = twod.call_function(X_grid)\n",
    "    # Reshape back to (N, N) for plotting\n",
    "    y_2d = y_grid.reshape(N, N)\n",
    "    \n",
    "    # Heatmap\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(y_2d, origin='lower', extent=(0,1,0,1), cmap='viridis', aspect='equal')\n",
    "    plt.colorbar(label='f(x, y)')\n",
    "    plt.title(\"Bimodal 2D Function (Heatmap)\")\n",
    "    plt.xlabel(\"x0\")\n",
    "    plt.ylabel(\"x1\")\n",
    "    plt.show()\n",
    "\n",
    "    # 3D surface\n",
    "    #fig = plt.figure(figsize=(8,6))\n",
    "    #ax = fig.add_subplot(111, projection='3d')\n",
    "    #ax.plot_surface(X0, X1, y_2d, cmap='viridis', edgecolor='none')\n",
    "    #ax.set_title(\"Bimodal 2D Function (Surface Plot)\")\n",
    "    #ax.set_xlabel(\"x0\")\n",
    "    #ax.set_ylabel(\"x1\")\n",
    "    #ax.set_zlabel(\"f(x, y)\")\n",
    "    #plt.show()\n",
    "\n",
    "    print(\"Max from grid search:\", np.max(y_2d))\n",
    "\n",
    "\n",
    "\n",
    "testmu1 = [random.random(),random.random()]\n",
    "testmu2 = [random.random(),random.random()]\n",
    "testalpha2 = random.uniform(0.3, 0.9)\n",
    "\n",
    "twod = two_d_test(mu1=testmu1, mu2=testmu2, alpha2=testalpha2)\n",
    "plot_twod_objective(twod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#week 4\n",
    "#pilot test n_d by using it to plot one_d\n",
    "x = np.linspace(0, 1, 500)\n",
    "testmu1 = 0.3\n",
    "testmu2 = 0.7\n",
    "testalpha1 = 1\n",
    "testalpha2 = 0.5\n",
    "testsigma1 = 0.1\n",
    "testsigma2 = 0.2\n",
    "oned = one_d_test(sigma1 = testsigma1, sigma2 = testsigma2, mu1=testmu1, mu2=testmu2, alpha1 =testalpha1, alpha2 = testalpha2)\n",
    "y = oned.call_function(x)\n",
    "\n",
    "# Plot the function\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, y, label=\"Bimodal Function\")\n",
    "plt.title(\"Bimodal Function\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "x = np.linspace(0, 1, 500)\n",
    "nd = n_d_test(sigma=[testsigma1, testsigma2], mu=[[[testmu1]], [[testmu2]]], alpha=[testalpha1, testalpha2])\n",
    "y = nd.call_function(x)\n",
    "\n",
    "# Plot the function\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, y, label=\"Bimodal Function\")\n",
    "plt.title(\"Bimodal Function\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "x2 = np.array([0.46])\n",
    "onedy2 = oned.call_function(x2)\n",
    "print(onedy2)\n",
    "ndy2 = nd.call_function(x2)\n",
    "print(ndy2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#week 4\n",
    "#pilot test n_d by using it to plot two_d\n",
    "testmu1 = [random.random(),random.random()]\n",
    "testmu2 = [random.random(),random.random()]\n",
    "testalpha2 = random.uniform(0.3, 0.9)\n",
    "testalpha1 = 1\n",
    "twod = two_d_test(mu1=testmu1, mu2=testmu2, alpha1 = 1, alpha2=testalpha2)\n",
    "plot_twod_objective(twod)\n",
    "\n",
    "nd = n_d_test(mu = [testmu1, testmu2], sigma=[0.1,0.1], alpha = [testalpha1, testalpha2] )\n",
    "plot_twod_objective(nd)\n",
    "\n",
    "# try 5 peaks\n",
    "mu5 = np.random.rand(5,2)\n",
    "sigma5 = (0.2, 0.1, 0.2, 0.1, 0.2)\n",
    "nd5 = n_d_test(mu=mu5, alpha=(1, 0.8,0.6, 0.6, 0.6), sigma = sigma5)\n",
    "plot_twod_objective(nd5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test acquisition functions on the 1d function\n",
    "\n",
    "noise_assumption = 1e-10 # noise assumption, a hyper-parameter\n",
    "\n",
    "input_bounds = [(0, 1)] # bounds for the input space\n",
    "\n",
    "#Experiment with lengthscale 0.1 to 0.5 in steps of 0.05\n",
    "# and kappa 0.1 to 3 in steps of 0.1\n",
    "\n",
    "def input_bounds_for_dim(dimensions):\n",
    "    return [(0, 1) for _ in range(dimensions)]\n",
    "\n",
    "def bounds_midpoint(input_bounds):\n",
    "    return np.array([(low + high) / 2.0 for low, high in input_bounds])\n",
    "\n",
    "def acquisition_UCB(x, model, ucb_kappa):\n",
    "    mean, std = model.predict(x.reshape(1, -1), return_std=True)\n",
    "    return mean + ucb_kappa * std\n",
    "\n",
    "def test_on_oned(rbf_lengthscale, ucb_acquisition_kappa, test_oned_function, max_iterations):\n",
    "    \n",
    "    objective_x = np.linspace(0, 1, 500)\n",
    "    objective_y = test_oned_function.call_function(objective_x)\n",
    "    objective_y_max = max(objective_y)\n",
    "\n",
    "    #quick plot objective function\n",
    "    #plt.figure(figsize=(3, 5))\n",
    "    #plt.plot(objective_x, objective_y, label=\"Objective\")\n",
    "    #plt.grid(True)\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    kernel = RBF(length_scale=rbf_lengthscale, length_scale_bounds='fixed')\n",
    "    model = GaussianProcessRegressor(kernel = kernel, alpha=noise_assumption)\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    # First point\n",
    "    x0 = bounds_midpoint(input_bounds)  # array([0.5])\n",
    "    X.append(x0)\n",
    "    Y.append(test_oned_function.call_function(x0))\n",
    "    i=0\n",
    "    #print(\"Objective max:\", objective_y_max)\n",
    "    while abs(max(Y) - objective_y_max) > 0.01:\n",
    "        i+=1\n",
    "        if i > max_iterations:\n",
    "            print(\"Max iterations reached\")\n",
    "            return 0\n",
    "        #print(\"Iteration\", i, \" Max found:\", max(Y))\n",
    "        # print(abs(max(Y) - objective_y_max))\n",
    "        # fit the model\n",
    "        model.fit(X, Y)\n",
    "            \n",
    "        # optimize the acquisition function\n",
    "        result = optimize.minimize(lambda x: -acquisition_UCB(x, model, ucb_acquisition_kappa), x0=bounds_midpoint(input_bounds), bounds=input_bounds)\n",
    "        x_new = result.x\n",
    "        y_new = test_oned_function.call_function(x_new)\n",
    "        \n",
    "        # add the new observation to the training set\n",
    "        X.append(x_new) #assumes 1d\n",
    "        Y.append(y_new)\n",
    "\n",
    "    return i\n",
    "\n",
    "def plot_oned_objective(oned):\n",
    "    objective_x = np.linspace(0, 1, 500)\n",
    "    objective_y = oned.call_function(objective_x)\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.plot(objective_x, objective_y, label=\"Objective\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ucb_kappa = 3\n",
    "#rbf_lengthscale = 0.2 # lengthscale parameter\n",
    "test_functions = []\n",
    "for i in range(3):\n",
    "    testmu1 = random.random()\n",
    "    testmu2 = random.random()\n",
    "    testalpha2 = random.uniform(0.3, 0.9)\n",
    "    oned = one_d_test(mu1=testmu1, mu2=testmu2, alpha2=testalpha2)\n",
    "    test_functions.append(oned)\n",
    "    plot_oned_objective(oned) # to see what we're dealing with\n",
    "\n",
    "results = []\n",
    "scenario_results = []\n",
    "for rbf_lengthscale in np.arange(0.05, 0.25, 0.1):\n",
    "    print(\"Lengthscale:\", rbf_lengthscale)\n",
    "    for kappa in np.arange(0.1, 2.00, 0.5):\n",
    "        ucb_kappa = round(kappa, 2)\n",
    "        print(\"Kappa:\", ucb_kappa)\n",
    "        fn = 0\n",
    "        fn_result = []\n",
    "        fn_result.append(rbf_lengthscale)\n",
    "        fn_result.append(ucb_kappa)\n",
    "        \n",
    "        scenario_description = f\"ls={rbf_lengthscale} - k={ucb_kappa}\"\n",
    "        result_list = []\n",
    "        for oned in test_functions:\n",
    "            iterations_required = test_on_oned(rbf_lengthscale, ucb_kappa, oned, 20)\n",
    "            fn_result.append(iterations_required)\n",
    "            #print(\"Lengthscale:\", rbf_lengthscale, \"Kappa:\", ucb_kappa, \"Function:\", fn, \"Needed:\", iterations_required)\n",
    "            result_list.append(iterations_required)\n",
    "            fn+=1\n",
    "        results.append(fn_result)\n",
    "        \n",
    "        scenario_result = ScenarioResult(scenario_description, result_list)\n",
    "        scenario_results.append(scenario_result)\n",
    "test_results = TestResults(scenario_results)\n",
    "\n",
    "output_results_csv(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on 2d functions\n",
    "def test_on_twod(rbf_lengthscale, ucb_acquisition_kappa, test_twod_function, max_iterations):\n",
    "    \n",
    "    twod_input_bounds = [(0, 1), (0,1)]\n",
    "\n",
    "    N = 100\n",
    "    x0_vals = np.linspace(0, 1, N)\n",
    "    x1_vals = np.linspace(0, 1, N)\n",
    "    X0, X1 = np.meshgrid(x0_vals, x1_vals)        # shape (N, N) each\n",
    "    objective_x = np.column_stack((X0.ravel(), X1.ravel()))  # shape (N*N, 2)\n",
    "    objective_y = test_twod_function.call_function(objective_x)\n",
    "    objective_y_max = max(objective_y)\n",
    "\n",
    "    kernel = RBF(length_scale=rbf_lengthscale)\n",
    "    model = GaussianProcessRegressor(kernel = kernel, alpha=noise_assumption)\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    # First point\n",
    "    initial_x = bounds_midpoint(twod_input_bounds)  # array([0.5])\n",
    "    X.append(initial_x)\n",
    "    Y.append(test_twod_function.call_function(initial_x))\n",
    "    for i in range(5):\n",
    "        starting_x = [random.random(), random.random()]\n",
    "        starting_y = test_twod_function.call_function(starting_x)\n",
    "        X.append(starting_x)\n",
    "        Y.append(starting_y)\n",
    "    \n",
    "    i=0\n",
    "\n",
    "    #print(\"Objective max:\", objective_y_max)\n",
    "    while abs(max(Y) - objective_y_max) > 0.01:\n",
    "        i+=1\n",
    "        # print(\"Max y:\", max(Y))\n",
    "        if i > max_iterations:\n",
    "            print(\"Max iterations reached\")\n",
    "            return 0\n",
    "        #print(\"Iteration\", i, \" Max found:\", max(Y))\n",
    "        # print(abs(max(Y) - objective_y_max))\n",
    "        # fit the model\n",
    "        model.fit(X, Y)\n",
    "            \n",
    "        # optimize the acquisition function\n",
    "        result = optimize.minimize(lambda x: -acquisition_UCB(x, model, ucb_acquisition_kappa), x0=initial_x, bounds=twod_input_bounds)\n",
    "        x_new = result.x\n",
    "        y_new = test_twod_function.call_function(x_new)\n",
    "        \n",
    "        # add the new observation to the training set\n",
    "        X.append(x_new)\n",
    "        Y.append(y_new)\n",
    "\n",
    "    return i\n",
    "\n",
    "test_functions = []\n",
    "for i in range(3): #5\n",
    "    testmu1 = [random.random(),random.random()]\n",
    "    testmu2 = [random.random(),random.random()]\n",
    "    testalpha2 = random.uniform(0.3, 0.9)\n",
    "    twod = two_d_test(mu1=testmu1, mu2=testmu2, alpha2=testalpha2)\n",
    "    test_functions.append(twod)\n",
    "    plot_twod_objective(twod) # to see what we're dealing with\n",
    "\n",
    "#test_on_twod(0.15, 0.4, test_functions[0], 20)\n",
    "\n",
    "results = []\n",
    "for rbf_lengthscale in np.arange(0.05, 0.5, 0.1):\n",
    "    print(\"Lengthscale:\", rbf_lengthscale)\n",
    "    for kappa in np.arange(0.1, 2.00, 0.5):\n",
    "        ucb_kappa = round(kappa, 2)\n",
    "        print(\"Kappa:\", ucb_kappa)\n",
    "        scenario_description = f\"ls={rbf_lengthscale} - k={ucb_kappa}\"\n",
    "        fn = 0\n",
    "        fn_result = []\n",
    "        fn_result.append(rbf_lengthscale)\n",
    "        fn_result.append(ucb_kappa)\n",
    "        result_list = []\n",
    "        for twod in test_functions:\n",
    "            iterations_required = test_on_twod(rbf_lengthscale, ucb_kappa, twod, 20)\n",
    "            fn_result.append(iterations_required)\n",
    "            result_list.append(iterations_required)\n",
    "            print(\"Lengthscale:\", rbf_lengthscale, \"Kappa:\", ucb_kappa, \"Function:\", fn, \"Needed:\", iterations_required)\n",
    "            fn+=1\n",
    "        results.append(fn_result)\n",
    "\n",
    "        scenario_result = ScenarioResult(scenario_description, result_list)\n",
    "        scenario_results.append(scenario_result)\n",
    "test_results = TestResults(scenario_results)\n",
    "\n",
    "output_results_csv(test_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the output, lengthscale 0.25 kappa 0.3 was about best for 2d\n",
    "\n",
    "for 1d, lengthscale 0.15 kappa 0.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# week 4 - set up test profiles to test the higher dimensions\n",
    "\n",
    "#Generate a random data point between 0 and 1 for the number of dimensions\n",
    "def random_point(dimensions):\n",
    "    return np.random.rand(dimensions)\n",
    "\n",
    "class TestProfile():\n",
    "    def __init__(self, dimensions, start_samples, maxima, std = 0.1):\n",
    "        self.dimensions = dimensions\n",
    "        self.start_samples = start_samples # number of samples to start with\n",
    "        self.maxima = maxima\n",
    "        self.std = std\n",
    "\n",
    "    def CreateFunctions(self, number):\n",
    "        profile_functions = []\n",
    "        for i in range(number):\n",
    "            mu = []\n",
    "            # assume 0.1 std for all gaussians\n",
    "            # assume alpha (relative height) = 1 for first peak and 0.5 for others\n",
    "            sigma = [self.std] * self.maxima\n",
    "            alpha = [1]\n",
    "\n",
    "            for m in range(self.maxima):\n",
    "                mu.append(random_point(self.dimensions))\n",
    "                if(m > 0):\n",
    "                    alpha.append(0.5)\n",
    "            ndt = n_d_test(mu=mu, sigma=sigma, alpha=alpha)\n",
    "            profile_functions.append (ndt)\n",
    "        return profile_functions\n",
    "\n",
    "def get_test_profile(function_number):\n",
    "    X, Y = get_function_data(function_number)\n",
    "    # Return a test profile matching what we know about the objective function\n",
    "    # Function 1 (2d): 2 maxima\n",
    "    # Function 2 (2d): \"a lot of local optima\" - use small standard deviation (0.05) and 10 peaks\n",
    "    # Function 4 (4d): \"a lot of local optima\" - use small standard deviation (0.05) and 20 peaks\n",
    "    # Function 5 (4d): 1 maximum\n",
    "    # For other functions - use the number of dimensions as the number of peaks\n",
    "    dimensions = X.shape[1]\n",
    "    start_samples = X.shape[0]\n",
    "    maxima = dimensions\n",
    "    std = 0.15\n",
    "    if(function_number == 1):\n",
    "        maxima = 2\n",
    "    elif(function_number ==2):\n",
    "        std = 0.1\n",
    "        maxima=10\n",
    "    elif(function_number == 4):\n",
    "        std = 0.05\n",
    "        maxima=20\n",
    "    elif(function_number==5):\n",
    "        maxima=1\n",
    "\n",
    "    return TestProfile(dimensions, start_samples, maxima, std)\n",
    "\n",
    "\n",
    "def test_on_n_d(test_profile: TestProfile, kernel, ucb_acquisition_kappa, test_function: n_d_test, max_iterations, n_grid = 20):\n",
    "    \n",
    "    # 1. Create a list of coordinate arrays, one for each dimension.\n",
    "    coords_1d = [np.linspace(0, 1, n_grid) for _ in range(test_profile.dimensions)]\n",
    "\n",
    "    # 2. Create the D-dimensional mesh.\n",
    "    #    Each element of `mesh` will be an array of shape (N, N, ..., N) [D times].\n",
    "    mesh = np.meshgrid(*coords_1d, indexing='ij')\n",
    "\n",
    "    # 3. Flatten each dimension, then stack them to get shape (N^D, D).\n",
    "    #    .ravel() flattens the array, and column_stack collects them into columns.\n",
    "    objective_x = np.column_stack([m.ravel() for m in mesh])\n",
    "\n",
    "    objective_y = test_function.call_function(objective_x)\n",
    "    objective_y_max = max(objective_y)\n",
    "\n",
    "    model = GaussianProcessRegressor(kernel = kernel, alpha=noise_assumption)\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    # First point\n",
    "    bounds = input_bounds_for_dim(test_profile.dimensions)\n",
    "    initial_x = bounds_midpoint(bounds)  \n",
    "    #X.append(initial_x)\n",
    "    #Y.append(test_function.call_function(initial_x))\n",
    "    for i in range(test_profile.start_samples):\n",
    "        starting_x = random_point(test_profile.dimensions)\n",
    "        starting_y = test_function.call_function([starting_x])\n",
    "        X.append(starting_x)\n",
    "        Y.append(starting_y[0])\n",
    "    \n",
    "    i=0\n",
    "    #print(\"Objective max:\", objective_y_max)\n",
    "    while abs(max(Y) - objective_y_max) > 0.01:\n",
    "        i+=1\n",
    "        # print(\"Max y:\", max(Y))\n",
    "        if i > max_iterations:\n",
    "            #print(\"Max iterations reached\")\n",
    "            return np.nan, np.nan\n",
    "        #print(\"Iteration\", i, \" Max found:\", max(Y))\n",
    "        # print(abs(max(Y) - objective_y_max))\n",
    "        # fit the model\n",
    "        model.fit(X, Y)\n",
    "            \n",
    "        # optimize the acquisition function\n",
    "        result = optimize.minimize(lambda x: -acquisition_UCB(x, model, ucb_acquisition_kappa), x0=initial_x, bounds=bounds)\n",
    "        x_new = result.x\n",
    "        y_new = test_function.call_function([x_new])\n",
    "        \n",
    "        # add the new observation to the training set\n",
    "        X.append(x_new)\n",
    "        Y.append(y_new[0])\n",
    "    trained_length_scale = 0\n",
    "    if hasattr(model, \"kernel_\"):\n",
    "        if(hasattr(model.kernel_, \"length_scale\")):\n",
    "            trained_length_scale = model.kernel_.length_scale\n",
    "    # print (trained_length_scale)\n",
    "    return i, trained_length_scale\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelWithParams():\n",
    "    def __init__(self, kernel, name, params):\n",
    "        self.kernel = kernel\n",
    "        self.name = name\n",
    "        self.params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "maternNu = 2.5\n",
    "\n",
    "def make_kernels_for_tests(lengthscale):\n",
    "    linearKernel = DotProduct(sigma_0=1.0)\n",
    "    linearWithParams = KernelWithParams(linearKernel, \"Linear (no noise)\", {})\n",
    "    rbfKernel = RBF(length_scale=lengthscale, length_scale_bounds=(0.001, 1))\n",
    "    rbfWithParams = KernelWithParams(rbfKernel, \"RBF\", {})\n",
    "    matern52Kernel = Matern(nu = maternNu, length_scale=lengthscale, length_scale_bounds=(0.001, 1))\n",
    "    matern52WithParams = KernelWithParams(matern52Kernel, \"Matern52\", {\"nu\": maternNu})\n",
    "    kernels = [linearWithParams, rbfWithParams, matern52WithParams]\n",
    "    \n",
    "    for alpha in np.arange(0.2, 2, 0.2):\n",
    "        rqKernel = RationalQuadratic(alpha = alpha, length_scale=lengthscale, length_scale_bounds=(0.001, 1))\n",
    "        kernels.append(KernelWithParams(rqKernel, \"RationalQuadratic\", {\"alpha\": alpha}))\n",
    "\n",
    "\n",
    "    return kernels\n",
    "\n",
    "def make_kernel_for_function(function_info):\n",
    "    kernel = None\n",
    "    match function_info.kernel_params[\"class\"]:\n",
    "        case \"Linear (no noise)\":\n",
    "            kernel = DotProduct(sigma_0=1.0)\n",
    "        case \"RBF\":\n",
    "            kernel = RBF(length_scale=function_info.kernel_lengthscale, length_scale_bounds=(0.001, 1))\n",
    "        case \"Matern52\":\n",
    "            kernel = Matern(nu = function_info.kernel_params[\"nu\"], length_scale=function_info.kernel_lengthscale, length_scale_bounds=(0.001, 1))\n",
    "        case \"RationalQuadratic\":\n",
    "            kernel = RationalQuadratic(alpha = function_info.kernel_params[\"alpha\"], length_scale=function_info.kernel_lengthscale, length_scale_bounds=(0.001, 1))\n",
    "        case _:\n",
    "            raise Exception (f\"Kernel class {function_info.kernel_params[\"class\"]} not matched\")\n",
    "\n",
    "    return KernelWithParams(kernel, function_info.kernel_params[\"class\"], function_info.kernel_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#tp1 = get_test_profile(1)\n",
    "#tf1 = tp1.CreateFunctions(1)[0]\n",
    "#iterations1 = test_on_n_d(tp1, 0.3, 1.00, tf1, 10)\n",
    "\n",
    "#tp3 = get_test_profile(3)\n",
    "#tf3 = tp3.CreateFunctions(1)[0]\n",
    "#iterations3 = test_on_n_d(tp3, 0.3, 1.00, tf3, 10)\n",
    "\n",
    "for fn in range(2, 9): # for each competition function\n",
    "    test_profile = get_test_profile(fn) #create the test profile\n",
    "    test_functions = []\n",
    "    test_functions = test_profile.CreateFunctions(4) #create gaussian process simulations\n",
    "    results = []\n",
    "    kernel_lengthscale = FunctionInfo(fn).kernel_lengthscale # previously trained lengthscales from competition function data\n",
    "    print(\"Lengthscale:\", kernel_lengthscale)\n",
    "    \n",
    "    kernels = make_kernels_for_tests(kernel_lengthscale)\n",
    "    scenario_results = []\n",
    "    for kernel in kernels:\n",
    "        for kappa in np.arange(0.1, 1.5, 0.3): # for kappa in range...\n",
    "            ucb_kappa = round(kappa, 2)\n",
    "            #print(\"Kappa:\", ucb_kappa)\n",
    "            result_line = []\n",
    "            kernelTypeName = kernel.name\n",
    "            if(len(kernel.params) > 0):\n",
    "                kernelTypeName += \" \" + str(kernel.params)\n",
    "            result_line.append(kernelTypeName)\n",
    "            result_line.append(kernel_lengthscale)\n",
    "            result_line.append(ucb_kappa)\n",
    "            result_list = []\n",
    "            scenario_description = f\"{kernelTypeName} - ls={kernel_lengthscale} - k={ucb_kappa}\"\n",
    "            print(scenario_description)\n",
    "            for test_function in test_functions: # Test the acquisition function configuration on each simulation\n",
    "                (iterations_required, trained_length_scale) = test_on_n_d(test_profile, kernel.kernel, ucb_kappa, test_function, 30, n_grid=20)\n",
    "                result_list.append(iterations_required)\n",
    "                result_line.append(iterations_required)\n",
    "                #result_line.append(trained_length_scale)\n",
    "                #print(\"Lengthscale:\", rbf_lengthscale, \"Kappa:\", ucb_kappa, \"Function:\", fn, \"Needed:\", iterations_required)\n",
    "            results.append(result_line)\n",
    "            \n",
    "            scenario_result = ScenarioResult(scenario_description, result_list)\n",
    "            scenario_results.append(scenario_result)\n",
    "    test_results = TestResults(scenario_results)\n",
    "    #print(results)\n",
    "    output_results_csv(test_results, f\"Function_{fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 1\n",
      "0.999999-0.784908\n",
      "Function 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mike\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified upper bound 1.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mike\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.500257-0.500039\n",
      "Function 3\n",
      "0.500001-0.500004-0.499999\n",
      "Function 4\n",
      "0.502787-0.488480-0.355693-0.387261\n",
      "Function 5\n",
      "perturb_max_start =  -0.055\n",
      "0.987554-0.470163-0.946567-0.105327\n",
      "Function 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mike\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified upper bound 1.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mike\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified upper bound 1.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.463126-0.317874-0.508172-0.723817-0.144808\n",
      "Function 7\n",
      "0.055316-0.488299-0.249433-0.216093-0.410181-0.731049\n",
      "Function 8\n",
      "0.108893-0.287056-0.194225-0.299992-0.537696-0.356217-0.306504-0.371320\n"
     ]
    }
   ],
   "source": [
    "# cutdown version that uses sample data instead of the initial random 5 and calls to the objective function, and suggests next point to explore.\n",
    "# Use that to do week 3 submissions.\n",
    "# Then, next week, start fitting on functions that are closer to the real ones in terms of local maxima/variance.\n",
    "\n",
    "def suggest_next(kernel, ucb_acquisition_kappa, function_num, initial_x = None):\n",
    "    model = GaussianProcessRegressor(kernel = kernel, alpha=noise_assumption)\n",
    "    X, Y = get_function_data(function_num)\n",
    "    dimensions = X.shape[1]\n",
    "    bounds = input_bounds_for_dim(dimensions)\n",
    "    if(initial_x is None):\n",
    "        initial_x = bounds_midpoint(bounds)\n",
    "    \n",
    "    model.fit(X, Y)\n",
    "\n",
    "    result = optimize.minimize(lambda x: -acquisition_UCB(x, model, ucb_acquisition_kappa), x0=initial_x, bounds=bounds)\n",
    "    return result.x, model.kernel_.length_scale\n",
    "\n",
    "\n",
    "for i in range(1,9):\n",
    "    X,y = get_function_data(i)\n",
    "    if(i==1):\n",
    "        y = scale_f1(y) #logarithmic scaling for f1\n",
    "    X_max = X[np.argmax(y)]\n",
    "    \n",
    "    print(\"Function\", i)\n",
    "    info = FunctionInfo(i)\n",
    "    if(info.perturb_max_start != 0):\n",
    "        print(\"perturb_max_start = \", info.perturb_max_start)\n",
    "        X_max += info.perturb_max_start\n",
    "    kernelWithParams = make_kernel_for_function(info)\n",
    "    sn, ls = suggest_next(kernelWithParams.kernel, info.ucb_kappa, i, initial_x=X_max)\n",
    "    formatted = format_for_submission(sn)\n",
    "    print(formatted)\n",
    "    #print(\"Trained length scale\", ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=5\n",
    "info_f = FunctionInfo(f)\n",
    "X,y = get_function_data(f)\n",
    "X_max = X[np.argmax(y)]\n",
    "X_max -= 0.055\n",
    "sn, ls = suggest_next(info_f.rbf_lengthscale, 30, f, initial_x=X_max)\n",
    "formatted = format_for_submission(sn)\n",
    "print(formatted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
