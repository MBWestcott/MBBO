
import numpy as np

week1_out = [0.0, -0.03634716524130564, -0.13995571712281177, -11.512791229057324, 351.7115420928652, -0.5971511450896173, 0.2910786825809617, 8.618272750952901]
week1_in = [np.array([0.00367, 0.9999 ]), 
            np.array([0.851999, 0.973204]), 
            np.array([0.747032, 0.28413 , 0.226329]), 
            np.array([0.169128, 0.756136, 0.275457, 0.528761]), 
            np.array([0.439601, 0.772709, 0.376277, 0.933269]), 
            np.array([0.232204, 0.132714, 0.53824 , 0.760706, 0.075595]), 
            np.array([0.476821, 0.248196, 0.242816, 0.576157, 0.162416, 0.290926]), 
            np.array([0.221603, 0.703755, 0.674607, 0.130295, 0.376739, 0.669444, 0.136655, 0.061316])]    

week2_out = [-1.2075460499722905e-18, 0.17608630702211278, -0.17239781799687137, -31.982880235497266, 1236.8846557000643, -2.451406055102475, 0.00010805707939840242, 5.178959940699899]
week2_in = [np.array([0.476035, 0.572563]), 
            np.array([0.641846, 0.498841]), 
            np.array([0., 0., 0.]), 
            np.array([0.953433, 0.895217, 0.812477, 0.618719]), 
            np.array([0.987523, 0.470227, 0.946409, 0.105412]), 
            np.array([3.40696e-01, 4.94179e-01, 2.10000e-05, 3.08050e-02, 9.39958e-01]), 
            np.array([0.88314 , 0.756642, 0.      , 0.      , 0.9     , 0.942719]), 
            np.array([0.993634, 0.968223, 0.979285, 0.397318, 0.965856, 0.955218, 0.006078, 0.024001])]

week3_out = [-2.118633970077695e-95, -0.1068943462941895, -0.005838531351604155, -2.6718044713157307, 32.0025, -1.4580645404618957, 0.4892165178828796, 9.9417237968706]

week3_in = [np.array([0.127849, 0.198491]), 
            np.array([0.246077, 0.656597]), 
            np.array([0.492581, 0.611593, 0.5     ]), 
            np.array([0.510358, 0.521985, 0.383995, 0.445439]), 
            np.array([0.5, 0.5, 0.5, 0.5]), 
            np.array([0.66336 , 0.      , 0.999999, 0.332984, 0.      ]), 
            np.array([0.      , 0.165185, 0.28681 , 0.      , 0.318109, 0.999999]), 
            np.array([0.119265, 0.254466, 0.117275, 0.24563 , 0.548426, 0.553172,  0.230111, 0.516062])]

week4_out = [-8.306597721001677e-27, 0.715790799340666, -0.00506242600241439, -3.2126105576284227, 31.94090504001378, -0.9205277885179105, 0.3911680928412005, 9.6899612812574]

week4_in = [np.array([0.24001 , 0.357107]),
                np.array([0.5, 0.5]), 
                np.array([0.5, 0.5, 0.5]), 
                np.array([0.549669, 0.508442, 0.413776, 0.413008]), 
                np.array([0.500102, 0.500102, 0.500102, 0.500102]), 
                np.array([0.563405, 0.      , 0.83134 , 0.999999, 0.      ]), 
                np.array([0.      , 0.626234, 0.280125, 0.      , 0.36777 , 0.451863]), 
                np.array([0.275027, 0.304704, 0.160147, 0.328388, 0.419169, 0.578759, 0.436166, 0.614079])]

week5_out = [1.517648729565899e-192, 0.509599138595138, -0.025681820315624142, -4.078914281244423, 629.9338529410855, -1.747233852094004, 0.39256467139392903, 9.7675674964181]

week5_in = [np.array([0.999999, 0.999999]), np.array([0.666698, 0.666698]), np.array([0.558875, 0.558874, 0.558875]), np.array([0.523385, 0.494608, 0.22783 , 0.357468]), np.array([0.932544, 0.415248, 0.89143 , 0.050433]), np.array([0.      , 0.687353, 0.      , 0.999999, 0.      ]), np.array([0.      , 0.56895 , 0.354465, 0.290165, 0.482077, 0.989692]), np.array([0.      , 0.047944, 0.315163, 0.115808, 0.571106, 0.59513 ,
       0.376754, 0.548807])]

week6_out = [-1.7808346077779874e-113, 0.8097867781489138, -0.021754112476429704, -2.3290209829198107, 1238.0344144400913, -0.3531644651233685, 1.4207771820533106, 9.863194426458]

week6_in = [np.array([0.999999, 0.784908]), 
            np.array([0.500257, 0.500039]), 
            np.array([0.500001, 0.500004, 0.499999]), 
            np.array([0.502787, 0.48848 , 0.355693, 0.387261]), 
            np.array([0.987554, 0.470163, 0.946567, 0.105327]), 
            np.array([0.463126, 0.317874, 0.508172, 0.723817, 0.144808]), np.array([0.055316, 0.488299, 0.249433, 0.216093, 0.410181, 0.731049]), np.array([0.108893, 0.287056, 0.194225, 0.299992, 0.537696, 0.356217,
       0.306504, 0.37132 ])]

week7_out = [5.711328105760199e-181, -0.12612902572151125, -0.0037570286950206317, -2.2184308662808827, 1266.6946029431565, -0.32396126685645454, 1.504001019324403, 9.8928466939651]

week7_in = [np.array([0.9, 0.2]), 
            np.array([0.3 , 0.85]), 
            np.array([0.499995, 0.499979, 0.500005]), 
            np.array([0.50976 , 0.499682, 0.361894, 0.410571]), 
            np.array([0.988196, 0.468239, 0.95064 , 0.102834]), 
            np.array([0.450692, 0.291679, 0.530446, 0.796956, 0.228417]), 
            np.array([0.052721, 0.47975 , 0.249304, 0.214388, 0.397125, 0.729761]), 
            np.array([0.034845, 0.333463, 0.207002, 0.20061 , 0.606274, 0.623629, 0.272586, 0.626177])]


week8_out = [1.517648729565899e-192, 0.5893282479824354, -0.003755538834828532, 0.4356154043374656, 1460.851692804078, -0.18800183363086395, 0.19725035466505603, 9.9573682720424]
week8_in = [np.array([0.999999, 0.999999]), np.array([0.880375, 0.44242 ]), np.array([0.499995, 0.5     , 0.5     ]), np.array([0.413247, 0.395992, 0.392364, 0.412961]), np.array([0.994996, 0.463549, 0.972149, 0.095332]), np.array([0.406513, 0.320061, 0.574077, 0.827518, 0.111625]), np.array([0.      , 0.496625, 0.365221, 0.119808, 0.004924, 0.95426 ]), np.array([0.14967 , 0.119732, 0.135655, 0.021701, 0.729461, 0.374063,
       0.189878, 0.729301])]

week9_out = [4.390042105420851e-96, 0.037068881495684734, -0.10714480689206822, 0.3993151787344975, 803.125544648536, -0.1724001097365032, 0.23946104243195931, 9.9945291309846]
week9_in = [np.array([0.824369, 0.939812]), np.array([0.907791, 0.408276]), np.array([0.85, 0.11, 0.62]), np.array([0.384057, 0.353891, 0.404024, 0.435841]), 
            np.array([0.94233 , 0.408227, 0.922877, 0.039362]), np.array([0.397563, 0.338641, 0.587087, 0.844029, 0.102478]), 
            np.array([0.      , 0.490308, 0.375843, 0.127935, 0.018695, 0.948211]), np.array([0.127542, 0.183196, 0.108019, 0.140588, 0.816319, 0.494041,       0.217229, 0.525747])]

week10_out = [-1.734852475761745e-60, 0.46227707004415614, -0.009638954094570346, 0.435657387239925, 1137.9195602632335, -0.1865922817915005, 2.550096898001736, 9.9671093365119]
week10_in = [np.array([0.798651, 0.868125]), np.array([0.747885, 0.473503]), np.array([0.499995, 0.5     , 0.5     ]), np.array([0.39583 , 0.371021, 0.410062, 0.404591]), np.array([0.25353 , 0.884504, 0.900956, 0.824813]), np.array([0.364457, 0.356583, 0.616022, 0.799995, 0.006197]), np.array([0.10458 , 0.251129, 0.512889, 0.201087, 0.332013, 0.794239]), np.array([0.134288, 0.233605, 0.131808, 0.159265, 0.963127, 0.416094,
       0.202944, 0.424184])]

week11_out = [5.268125071343981e-05, 0.26354284901897973, -0.018755122077235682, 0.4429214317724761, 1126.4772097185373, -0.1487138892266534, 2.711784867091037, 9.9833600423085]

week11_in = [np.array([0.580172, 0.588216]), np.array([0.751489, 0.488207]), np.array([0.499995, 0.52    , 0.5     ]), 
             np.array([0.396506, 0.371179, 0.408664, 0.406183]), np.array([0.250547, 0.881019, 0.898804, 0.829029]), 
             np.array([0.358861, 0.36118 , 0.620833, 0.798651, 0.012107]), np.array([0.138608, 0.241216, 0.512483, 0.227211, 0.353446, 0.779906]), 
             np.array([0.154828, 0.150755, 0.135927, 0.167159, 0.814302, 0.413704, 0.196015, 0.437325])]

week12_out = [-6.925388810586621e-16, 0.5708236653648293, -0.041690964649215845, 0.4435486780130913, 1127.910712944417, -0.2216771831190694, 2.75544898316302, 9.9798331901746]
week12_in = [np.array([0.55, 0.49]), np.array([0.737314, 0.482462]), np.array([0.499995, 0.5     , 0.499995]), np.array([0.396562, 0.371215, 0.408446, 0.40644 ]), np.array([0.250935, 0.881475, 0.899084, 0.828472]), np.array([0.35228 , 0.366968, 0.627038, 0.798081, 0.      ]), np.array([0.151874, 0.231648, 0.520087, 0.236592, 0.363845, 0.772516]), np.array([0.15161 , 0.188692, 0.138602, 0.160302, 0.944244, 0.509145,
       0.211368, 0.750638])]

week13_out = [-1.734852475761745e-60, 0.5887408774661069, -0.01166535120889699, 0.435657387239925, 1137.9195602632335, -0.23233602537565953, 2.550096898001736, 9.9945291309846]
week13_in = [np.array([0.798651, 0.868125]), np.array([0.747885, 0.473503]), np.array([0.499995, 0.5     , 0.5     ]), np.array([0.39583 , 0.371021, 0.410062, 0.404591]), np.array([0.25353 , 0.884504, 0.900956, 0.824813]), np.array([0.364457, 0.356583, 0.616022, 0.799995, 0.006197]), np.array([0.10458 , 0.251129, 0.512889, 0.201087, 0.332013, 0.794239]), np.array([0.127542, 0.183196, 0.108019, 0.140588, 0.816319, 0.494041,
       0.217229, 0.525747])]


week14_out = [-3.237793504060581e-19, -0.07630245334315977, -0.003828212300923771, 0.2811526237409194, 3412.670037726836, -0.21588726740765765, 2.7745126189498346, 9.979321412206]
week14_in = [np.array([0.48, 0.27]), np.array([0.33, 0.44]), np.array([0.498  , 0.498  , 0.50002]), np.array([0.391959, 0.380273, 0.406908, 0.406706]), np.array([0.366656, 0.979958, 0.99824 , 0.930244]), np.array([0.350331, 0.36859 , 0.628943, 0.797925, 0.      ]), np.array([0.157764, 0.227863, 0.525279, 0.240713, 0.369344, 0.76671 ]), np.array([0.141255, 0.132977, 0.107644, 0.235194, 0.723225, 0.563478,
       0.196206, 0.489455])]

week15_out = [0.5198124628573706, 0.8584016928716146, -0.009081571661836449, 0.28323120083276665, 4266.666562034985, -0.22589366304223552, 2.7831835147437474, 9.9868265981395]
week15_in = [np.array([0.62 , 0.607]), np.array([0.500271, 0.500041]), np.array([0.499995, 0.499985, 0.5     ]), np.array([0.391351, 0.380243, 0.407555, 0.406354]), np.array([0.413634, 0.999999, 0.999999, 0.97853 ]), np.array([0.348246, 0.37055 , 0.631251, 0.797562, 0.      ]), np.array([0.155885, 0.227187, 0.531089, 0.239434, 0.371577, 0.761383]), np.array([0.074853, 0.113799, 0.139231, 0.071096, 0.747064, 0.495198,
       0.166412, 0.533955])]

queries = [week1_in, week2_in, week3_in, week4_in, week5_in, week6_in, week7_in, week8_in, week9_in, week10_in, week11_in, week12_in, week13_in, week14_in, week15_in]
responses = [week1_out, week2_out, week3_out, week4_out, week5_out, week6_out, week7_out, week8_out, week9_out, week10_out, week11_out, week12_out, week13_out, week14_out, week15_out]

def load_initial_data(function_number: int, include_set2: bool = True):
    ary_in = np.load(f'../data/raw/initial_data/function_{function_number}/initial_inputs.npy')
    ary_out = np.load(f'../data/raw/initial_data/function_{function_number}/initial_outputs.npy')
    if(include_set2):
        ary2_in = np.load(f'../data/raw/initial_data2/function_{function_number}/initial_inputs.npy')
        ary2_out = np.load(f'../data/raw/initial_data2/function_{function_number}/initial_outputs.npy')
        ary_in = np.vstack((ary_in, ary2_in))
        ary_out = np.append(ary_out, ary2_out)

    return ary_in, ary_out

def get_function_data(function_number: int, include_set2: bool = True, include_observed: bool = True):
    ary_in, ary_out = load_initial_data(function_number, include_set2)
    if include_observed:    
        for r in responses:
            ary_out = np.append(ary_out, r[function_number - 1])
        for q in queries:
            ary_in = np.vstack((ary_in, q[function_number - 1]))
    return ary_in, ary_out

class FunctionInfo():
    # week 7 - function 1 - need to find 2nd optimum which seems to be around [0.9, 0.2] - keep exploring around there (changed kappa from 0.1 to 0.8)
    # function 2 - "lot of local optima" so keep exploring too, especially unexplored areas - top left (around [0.3, 0.85]) and bottom right (around [0.775, 0.275])
    rbf_lengthscales = [0.00421, 0.0544, 0.016, 3.51, 0.0942, 3.04, 0.198, 2.38 ] # functions 2 and 8 didn't find optimal lengthscale in training
    default_lengthscale_lb = 0.001
    default_lengthscale_ub = 20.0
    lengthscale_bounds_list = [(default_lengthscale_lb, default_lengthscale_ub)] * 8
    lengthscale_bounds_list[0] = (0.0001, 20) #f1
    lengthscale_bounds_list[1] = (0.0001, 50)
    lengthscale_bounds_list[2] = (0.0001, 80) #f3
    constant_value_bounds_list = [(1e-5, 1e5)] * 8 # constant kernel default value bounds
    constant_value_bounds_list[7] = (1e-5, 1e7) #f8
    ucb_kappas = [0.8, 0.5, 0.2, 0.7, 0.1, 0.7, 0.4, 0.4] # lowered for exploitation excepr 1,2,4,5
    #ucb_kappas = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
    #ucb_kappas = ucb_kappas * 4 # increase for random forest regressor
    #ucb_kappas = [2, 0.5, 0.00001, 0.8, 0.4, 0.8, 0.8, 0.8]
    #ucb_kappas = [0.8, 0.5, 0.00001, 0.8, 0.4, 0.8, 0.8, 0.8] # only got successful calibration for first 3. Default to 0.8 for the rest (high because still exploring) 
                                                              # - except function 5 which is unimodal so can exploit more.
                                                              # Function 3 - aim is to reduce bad side effects of drug combination - have a maximum around 0.5,0.5,0.5 so from week 5 on, exploiting that
    acq_xis = [2.9, 2.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9] # default to 0.1 for all functions                                                    
    #perturb_max_starts = [0,0,0,0,0.055,0,0,0.1] #having trouble getting function 5 to explore a little more away from its maximum - nudge
    perturb_max_starts = [0,0,0,0,0,0,0,0] 
    kernel_params_list=[{"class": "RationalQuadratic", "alpha": 0.949, "alphabounds": (1e-5, 1e5)},
                   {"class": "RationalQuadratic", "alpha": 2.0, "alphabounds": (1e-8, 1e5)},
                   {"class": "Linear (no noise)", "alpha": 1.0, "alphabounds": (1e-5, 1e5)},
                   {"class": "RationalQuadratic", "alpha": 0.6, "alphabounds": (1e-5, 1e5)},
                   {"class": "RationalQuadratic", "alpha": 0.2, "alphabounds": (1e-5, 1e5)}, #f5 = mainly NaN
                   {"class": "RationalQuadratic", "alpha":0.0417, "alphabounds": (1e-5, 1e5), "nu":2.5}, #f6 - mainly NaN
                   {"class": "RationalQuadratic", "alpha": 0.308, "alphabounds": (1e-5, 1e5)},
                   {"class": "RBF", "alpha": 1.0, "alphabounds": (1e-5, 1e7)}]

    def __init__(self, function_number):
        self.function_number = function_number
        function_ix = function_number - 1
        self.kernel_lengthscale = self.rbf_lengthscales[function_ix]
        self.ucb_kappa = self.ucb_kappas[function_ix]
        self.acq_xi = self.acq_xis[function_ix]
        self.kernel_params = self.kernel_params_list[function_ix]
        self.perturb_max_start = self.perturb_max_starts[function_ix]
        self.n_restarts_optimizer = 0 if self.kernel_params["class"] in ["RBF", "Linear (no noise)"] else 10 # use restarts optimizer for more complex kernels
        self.lengthscale_bounds = self.lengthscale_bounds_list[function_ix]
        self.constant_value_bounds = self.constant_value_bounds_list[function_ix]


def scale(function_num, values):
    #function 1 - values mostly very close to 0
    if function_num != 1:
        return values
    
    # Step 1: Replace zeros with a small positive value to avoid log(0)
    epsilon = 1e-250  # A very small number
    values_safe = np.where(values == 0, epsilon, values)

    # Step 2: Take the logarithm of absolute values
    log_values = np.log10(np.abs(values_safe))

    # Step 3: Normalize to the range [-1, 1]
    log_min, log_max = np.min(log_values), np.max(log_values)
    scaled_values = 2 * (log_values - log_min) / (log_max - log_min) - 1

    # Step 4: Restore signs
    return np.sign(values) * np.abs(scaled_values)

def reduce(function_num, values):
    """
    Reduce the number of dimensions to the most important ones for the given function
    """
    important_dimensions = {}
    important_dimensions = {8:[0,2,6]} # function 8: based on coefficients [-1.6245557  -0.46852827 -2.36121139 -0.50061563  0.15028904 -0.18675851 -1.20356151  0.24547701]
    if function_num not in important_dimensions:
        return values
    return values[:, important_dimensions[function_num]]

def is_close(new_x, existing_x, threshold = 0.1):
    distances = np.linalg.norm(existing_x - new_x, axis=1)
    min_distance = distances.min()
    closest_existing = existing_x[distances.argmin()]
    
    too_close = min_distance < threshold
    
    return (too_close, min_distance, closest_existing)
    
    